# Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification
## Abstract
Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability.
> ### Please read our [article](https://arxiv.org/abs/) for further information.

## Dataset Files
- **`llama_aaai`**, **`gemma_aaai`**, and **`phi_aaai`** contain the datasets corresponding to each language model (LM) used in our experiments.  
  Each file includes the following fields:
  - **`label`** — The ground-truth classification label for each sample.  
  - **`model_input`** — The original context or prompt provided to the language model as input for inference.  
  - **`model_output`** — The language model’s generated output, including both its classification and accompanying reasoning.  
  - **`segmented_output`** — The reasoning content from `model_output`, segmented into discrete reasoning points.  
  - **`factuality`** — Ground-truth annotations indicating which reasoning points in `segmented_output` contain factual hallucinations (i.e., statements contradicting `model_input`).  
  - **`deberta_finetuned`**, **`roberta_finetuned`**, **`bart_finetuned`** — Predictions from verifier models (DeBERTa, RoBERTa, and BART) identifying reasoning points that contain factual hallucinations.  
  - **`llama_foundation`** and **`llama_finetuned`** — Factual hallucination predictions from the foundation and fine-tuned versions of LLaMA, based on `model_output` generated by LLaMA.  
    (Equivalent datasets are provided for Gemma and Phi models.)

## Metric Files
- **`metrics_self_reflection`** — Records the classification performance of language models during both:  
  - Initial inference, and  
  - Adaptive inference after self-reflection on factual hallucinations.  

- **`metrics_verifier_deberta`**, **`metrics_verifier_roberta`**, and **`metrics_verifier_bart`** — Record the classification performance of language models during:  
  - Initial inference, and  
  - Adaptive inference guided by feedback from corresponding verifier models detecting factual hallucinations.

## Citation
- Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification
